{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('RL': conda)"
  },
  "interpreter": {
   "hash": "96f06199865e12de6fa2c5acd33b7d661a80a27a845f224073234533a3ad5c65"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as utils\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "seed = 1\n",
    "log_interval = 10\n",
    "T.manual_seed(seed)\n",
    "device = T.device('cuda' if T.cuda.is_available() else 'cpu')\n",
    "print('Device : ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "train_loader = T.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/', train=True, download=False,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = T.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        # decoder\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = T.exp(0.5*logvar)\n",
    "        eps = T.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return T.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * T.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with T.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = T.cat([data[:n],\n",
    "                                      recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'results_note/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0/60000 (0%)]\tLoss: 117.065254\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 114.811470\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 114.763657\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 119.434021\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 113.214653\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 119.106102\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 113.529953\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 113.439072\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 113.291817\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 116.415443\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 116.494415\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 115.286537\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 113.007622\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 116.642227\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 116.871040\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 109.764984\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 113.505577\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 113.196274\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 112.494019\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 112.664490\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 118.406967\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 120.611984\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 111.625015\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 115.878860\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 116.444016\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 115.961807\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 116.288139\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 111.409119\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 116.073929\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 120.110191\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 116.082420\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 116.792313\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 113.134201\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 113.591148\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 113.367043\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 113.575348\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 114.748688\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 114.765419\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 109.309380\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 112.361015\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 114.221237\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 112.348686\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 114.944534\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 112.313332\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 114.665764\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 112.995766\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 111.327759\n",
      "====> Epoch: 3 Average loss: 114.5135\n",
      "====> Test set loss: 111.3922\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 112.132607\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 111.089325\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 112.160500\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 115.602043\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 108.517586\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 113.768875\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 109.534943\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 116.180992\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 117.233498\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 112.584213\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 112.863190\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 115.558784\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 117.418655\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 110.254135\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 108.657501\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 109.931747\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 111.774269\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 115.147118\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 108.271019\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 110.851166\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 110.646759\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 109.112228\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 110.549950\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 111.100662\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 111.411430\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 108.967163\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 110.805458\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 114.398247\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 110.091080\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 111.186234\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 111.714981\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 113.280502\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 111.391472\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 113.090645\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 111.534462\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 110.583466\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 108.550285\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 108.596954\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 105.872910\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 112.101570\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 108.595047\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 113.023209\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 115.514542\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 112.026337\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 106.813766\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 115.450668\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 109.772964\n",
      "====> Epoch: 4 Average loss: 111.4680\n",
      "====> Test set loss: 109.4375\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 111.093338\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 113.147766\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 114.044945\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 115.255646\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 109.544708\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 112.193558\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 111.561615\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 108.491295\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 110.463585\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 109.339851\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 109.776649\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 110.965164\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 109.833641\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 110.102142\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 113.630112\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 117.236450\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 107.693314\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 112.333023\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 109.685066\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 108.932037\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 113.858757\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 112.631493\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 111.136475\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 109.713852\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 107.256180\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 106.442947\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 104.638184\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 111.340698\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 108.101578\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 107.274055\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 109.475105\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 113.954605\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 110.354492\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 110.400841\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 107.878357\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 109.645256\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 109.346024\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 108.439255\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 113.484390\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 106.160416\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 110.264328\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 113.377548\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 108.005066\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 113.697388\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 109.020157\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 111.325294\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 109.457611\n",
      "====> Epoch: 5 Average loss: 109.7317\n",
      "====> Test set loss: 108.2053\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 112.162506\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 108.127403\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 112.525078\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 105.221786\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 105.079933\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 109.430908\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 108.570572\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 107.718384\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 111.322899\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 108.860939\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 106.706406\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 113.826538\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 105.287628\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 111.712952\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 110.764175\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 109.411438\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 108.057152\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 109.295174\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 110.768570\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 109.766685\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 108.138535\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 104.938675\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 108.326584\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 105.412201\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 111.493561\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 104.936203\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 108.752426\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 110.996292\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 106.718773\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 109.704010\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 107.738266\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 104.897804\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 109.435196\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 107.656097\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 106.590858\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 111.613266\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 103.199272\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 106.567688\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 108.283455\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 106.906273\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 107.612122\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 108.487198\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 102.606995\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 108.547050\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 109.021881\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 112.853516\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 108.387802\n",
      "====> Epoch: 6 Average loss: 108.5696\n",
      "====> Test set loss: 107.3147\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 107.959084\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 109.081909\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 107.462524\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 109.016098\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 107.469849\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 108.930710\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 109.244347\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 102.739914\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 107.890419\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 109.346153\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 104.636215\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 108.556000\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 104.175102\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 106.787338\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 107.095474\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 104.612923\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 104.871689\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 109.774239\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 109.221527\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 106.819908\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 108.349091\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 108.430832\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 111.536163\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 111.922424\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 102.423004\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 105.127716\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 106.377243\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 108.120880\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 110.142204\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 106.304314\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 108.688179\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 106.867332\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 105.459412\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 108.943176\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 107.737251\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 110.991364\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 107.460815\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 108.310341\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 107.720520\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 108.897224\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 109.736664\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 107.314705\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 105.455688\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 108.337379\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 109.714195\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 102.000015\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 104.287766\n",
      "====> Epoch: 7 Average loss: 107.7151\n",
      "====> Test set loss: 106.7833\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 105.899734\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 106.393097\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 104.710045\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 103.414818\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 103.202301\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 109.390701\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 106.616409\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 104.610146\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 109.771408\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 106.130478\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 108.645645\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 103.588196\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 110.783348\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 110.641144\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 102.100357\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 107.833992\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 100.114517\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 107.181702\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 109.928070\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 108.586334\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 104.154373\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 109.794510\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 109.742966\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 110.468262\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 105.680069\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 110.616440\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 107.124680\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 109.219528\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 108.063934\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 104.922592\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 106.628830\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 109.395248\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 105.746368\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 108.028275\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 107.766083\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 104.914581\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 105.857483\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 107.604233\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 103.279182\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 109.556107\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 107.823051\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 112.079773\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 107.310265\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 108.161819\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 106.290695\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 108.921539\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 104.427902\n",
      "====> Epoch: 8 Average loss: 107.0943\n",
      "====> Test set loss: 106.3881\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 109.685089\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 108.926018\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 108.648293\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 102.634750\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 107.789032\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 109.063019\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 104.780876\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 109.142883\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 106.570496\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 109.561722\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 110.526375\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 108.638283\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 106.725822\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 108.188644\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 103.556740\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 103.812477\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 104.023506\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 105.811646\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 108.084396\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 101.841293\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 104.006752\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 104.503517\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 109.413208\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 105.683922\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 107.451706\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 108.747269\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 108.400772\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 109.017029\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 109.734627\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 110.093086\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 107.257980\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 113.008560\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 105.511169\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 105.745941\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 105.807388\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 106.306808\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 108.394287\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 107.446915\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 109.709915\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 106.891495\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 104.893814\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 106.199028\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 103.718842\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 107.504654\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 105.541168\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 106.712280\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 107.550072\n",
      "====> Epoch: 9 Average loss: 106.6288\n",
      "====> Test set loss: 105.7393\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 104.683182\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 106.778046\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 105.190536\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 105.401337\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 108.416321\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 106.259789\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 105.691574\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 107.476303\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 109.970772\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 104.830719\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 107.003677\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 105.257828\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 111.028214\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 108.709320\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 102.980515\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 108.346764\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 104.697479\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 106.122513\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 111.325943\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 104.007050\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 104.138626\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 106.854034\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 104.903145\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 108.028534\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 102.204933\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 110.004677\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 104.178246\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 105.605858\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 107.439896\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 106.049637\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 107.681732\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 108.895218\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 105.287079\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 106.628021\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 110.716484\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 101.313461\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 102.048515\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 103.790710\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 106.301880\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 103.745010\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 103.954704\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 100.246330\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 107.399117\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 104.877502\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 103.000427\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 103.352036\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 100.785240\n",
      "====> Epoch: 10 Average loss: 106.1623\n",
      "====> Test set loss: 105.4583\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    with T.no_grad():\n",
    "        sample = T.randn(64, 20).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(64, 1, 28, 28),\n",
    "                    'results_note/sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}